#date: 2025-11-13T17:02:59Z
#url: https://api.github.com/gists/c1c2c32c02ad6b73f59da7fc63add2f0
#owner: https://api.github.com/users/wangwei334455

"""
æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å™¨ï¼ˆè¡Œä¸šæœ€ä½³å®è·µï¼‰

ã€è®¾è®¡åŸåˆ™ã€‘
1. å¯åŠ¨æ—¶åˆå§‹åŒ–ï¼šåç«¯å¯åŠ¨æ—¶è‡ªåŠ¨ä»MT5æ‹‰å–å†å²æ•°æ®å¹¶è¡¥ç©º
2. å®šæœŸå®Œæ•´æ€§æ£€æŸ¥ï¼šå®šæœŸæ£€æŸ¥Kçº¿æ—¶é—´é—´éš”ï¼Œè‡ªåŠ¨ä¿®å¤
3. å¢é‡ä¿®å¤ï¼šåªä¿®å¤æœ€è¿‘çš„æ•°æ®ï¼Œå†å²æ•°æ®è§†ä¸ºå›ºå®š
4. æ•°æ®è´¨é‡ç›‘æ§ï¼šç›‘æ§ç¼ºå¤±ç‡ã€é‡å¤ç‡ã€æ—¶é—´é—´éš”å¼‚å¸¸
5. åŸå­æ“ä½œï¼šä½¿ç”¨Redisäº‹åŠ¡ç¡®ä¿æ•°æ®ä¸€è‡´æ€§

ã€æ•°æ®å®Œæ•´æ€§æ ‡å‡†ã€‘
- æ—¶é—´é—´éš”ï¼šå¿…é¡»ä¸¥æ ¼ç­‰äºå‘¨æœŸï¼ˆ60ç§’ã€300ç§’ç­‰ï¼‰
- æ—¶é—´è¿ç»­æ€§ï¼šä¸èƒ½æœ‰ç¼ºå¤±çš„Kçº¿
- æ•°æ®å”¯ä¸€æ€§ï¼šç›¸åŒæ—¶é—´æˆ³åªèƒ½æœ‰ä¸€æ¡Kçº¿
- æ•°æ®å®Œæ•´æ€§ï¼šOHLCVå­—æ®µå¿…é¡»å®Œæ•´
"""
import json
import time
import redis
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from loguru import logger

from config.redis_config import REDIS_CONFIG


class DataIntegrityChecker:
    """
    æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å™¨ï¼ˆè¡Œä¸šæœ€ä½³å®è·µï¼‰
    
    ã€èŒè´£ã€‘
    1. å¯åŠ¨æ—¶æ•°æ®åˆå§‹åŒ–ï¼šä»MT5æ‹‰å–å†å²æ•°æ®å¹¶è¡¥ç©º
    2. å®šæœŸå®Œæ•´æ€§æ£€æŸ¥ï¼šæ£€æŸ¥Kçº¿æ—¶é—´é—´éš”ï¼Œè‡ªåŠ¨ä¿®å¤
    3. æ•°æ®è´¨é‡ç›‘æ§ï¼šç»Ÿè®¡ç¼ºå¤±ç‡ã€é‡å¤ç‡ã€å¼‚å¸¸ç‡
    4. å¢é‡ä¿®å¤ï¼šåªä¿®å¤æœ€è¿‘Næ ¹Kçº¿ï¼Œå†å²æ•°æ®è§†ä¸ºå›ºå®š
    """
    
    def __init__(self, symbol: str = "BTCUSDm"):
        self.symbol = symbol
        self.redis_client = redis.Redis(
            host=REDIS_CONFIG.get('host', 'localhost'),
            port=REDIS_CONFIG.get('port', 6379),
            db=REDIS_CONFIG.get('db', 0),
            decode_responses=True
        )
        
        self.kline_key = f"kline:{symbol}:1m"
        
        # æ•°æ®è´¨é‡ç»Ÿè®¡
        self.stats = {
            'total_klines': 0,
            'missing_klines': 0,
            'duplicate_klines': 0,
            'invalid_intervals': 0,
            'filled_klines': 0,
        }
        
        logger.info(f"æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å™¨åˆå§‹åŒ–: {symbol}")
    
    def check_time_interval(self, klines: List[Dict[str, Any]], timeframe: str = '1m') -> Tuple[List[int], int]:
        """
        æ£€æŸ¥Kçº¿æ—¶é—´é—´éš”ï¼ˆè¡Œä¸šæœ€ä½³å®è·µï¼šä¸¥æ ¼æ£€æŸ¥ï¼‰
        
        Args:
            klines: Kçº¿åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
            timeframe: æ—¶é—´å‘¨æœŸ
            
        Returns:
            (å¼‚å¸¸ä½ç½®åˆ—è¡¨, ç¼ºå¤±Kçº¿æ€»æ•°)
        """
        if len(klines) < 2:
            return [], 0
        
        # æ—¶é—´å‘¨æœŸæ˜ å°„ï¼ˆç§’ï¼‰
        timeframe_seconds = {
            '1m': 60, '5m': 300, '15m': 900, '30m': 1800,
            '1h': 3600, '4h': 14400, '1d': 86400
        }
        expected_interval = timeframe_seconds.get(timeframe, 60)
        
        anomalies = []
        total_missing = 0
        
        for i in range(len(klines) - 1):
            prev_time = klines[i].get('time', 0)
            current_time = klines[i + 1].get('time', 0)
            actual_interval = current_time - prev_time
            
            # ä¸¥æ ¼æ£€æŸ¥ï¼šå…è®¸1ç§’å®¹å·®ï¼ˆç½‘ç»œå»¶è¿Ÿã€æ—¶é’ŸåŒæ­¥ï¼‰
            if actual_interval != expected_interval:
                if actual_interval > expected_interval + 1:
                    # ç¼ºå¤±Kçº¿
                    missing_count = (actual_interval // expected_interval) - 1
                    anomalies.append(i)
                    total_missing += missing_count
                    logger.debug(f"ä½ç½®{i}: ç¼ºå¤±{missing_count}æ ¹Kçº¿ (é—´éš”={actual_interval}ç§’, æœŸæœ›={expected_interval}ç§’)")
                elif actual_interval < expected_interval - 1:
                    # å¼‚å¸¸é—´éš”ï¼ˆå¯èƒ½æ˜¯é‡å¤æˆ–é”™è¯¯æ•°æ®ï¼‰
                    anomalies.append(i)
                    logger.warning(f"ä½ç½®{i}: å¼‚å¸¸é—´éš”={actual_interval}ç§’ (æœŸæœ›={expected_interval}ç§’)")
        
        return anomalies, total_missing
    
    def fill_missing_klines(self, klines: List[Dict[str, Any]], timeframe: str = '1m') -> List[Dict[str, Any]]:
        """
        å¡«å……ç¼ºå¤±çš„Kçº¿ï¼ˆè¡Œä¸šæœ€ä½³å®è·µï¼šç²¾ç¡®è®¡ç®—ï¼‰
        
        Args:
            klines: Kçº¿åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
            timeframe: æ—¶é—´å‘¨æœŸ
            
        Returns:
            å¡«å……åçš„Kçº¿åˆ—è¡¨
        """
        if len(klines) < 2:
            return klines
        
        timeframe_seconds = {
            '1m': 60, '5m': 300, '15m': 900, '30m': 1800,
            '1h': 3600, '4h': 14400, '1d': 86400
        }
        expected_interval = timeframe_seconds.get(timeframe, 60)
        
        filled_klines = [klines[0]]
        
        for i in range(1, len(klines)):
            prev_kline = klines[i - 1]
            current_kline = klines[i]
            
            prev_time = prev_kline.get('time', 0)
            current_time = current_kline.get('time', 0)
            actual_interval = current_time - prev_time
            
            # å¦‚æœæ—¶é—´é—´éš”å¤§äºæœŸæœ›é—´éš”ï¼Œå¡«å……ç¼ºå¤±çš„Kçº¿
            if actual_interval > expected_interval + 1:
                kline_count_in_gap = actual_interval // expected_interval
                missing_count = kline_count_in_gap - 1
                
                if missing_count >= 1:
                    prev_close = prev_kline.get('close', 0)
                    if prev_close > 0:
                        for j in range(1, missing_count + 1):
                            missing_time = prev_time + (j * expected_interval)
                            
                            filled_kline = {
                                'time': missing_time,
                                'open': prev_close,
                                'high': prev_close,
                                'low': prev_close,
                                'close': prev_close,
                                'volume': 0,
                                'real_volume': 0,
                                'is_filled': True
                            }
                            filled_klines.append(filled_kline)
                            self.stats['filled_klines'] += 1
            
            filled_klines.append(current_kline)
        
        return filled_klines
    
    def deduplicate_klines(self, klines: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å»é‡Kçº¿æ•°æ®ï¼ˆç›¸åŒæ—¶é—´æˆ³åªä¿ç•™æœ€æ–°çš„ï¼‰
        
        Args:
            klines: Kçº¿åˆ—è¡¨
            
        Returns:
            å»é‡åçš„Kçº¿åˆ—è¡¨
        """
        seen_times = {}
        duplicates = 0
        
        for kline in klines:
            kline_time = kline.get('time', 0)
            if kline_time > 0:
                if kline_time in seen_times:
                    # ä¿ç•™æœ€æ–°çš„æ•°æ®ï¼ˆvolumeæ›´å¤§çš„ï¼‰
                    if kline.get('volume', 0) > seen_times[kline_time].get('volume', 0):
                        seen_times[kline_time] = kline
                        duplicates += 1
                else:
                    seen_times[kline_time] = kline
        
        self.stats['duplicate_klines'] = duplicates
        
        unique_klines = list(seen_times.values())
        unique_klines.sort(key=lambda x: x.get('time', 0))
        
        return unique_klines
    
    def initialize_from_mt5(self, count: int = 2880, timeframe: str = '1m') -> bool:
        """
        å¯åŠ¨æ—¶ä»MT5åˆå§‹åŒ–å†å²æ•°æ®ï¼ˆè¡Œä¸šæœ€ä½³å®è·µï¼šå¯åŠ¨æ—¶è‡ªåŠ¨æ‹‰å–ï¼‰
        
        Args:
            count: æ‹‰å–æ•°é‡ï¼ˆé»˜è®¤2880æ ¹ï¼Œå³2å¤©M1æ•°æ®ï¼‰
            timeframe: æ—¶é—´å‘¨æœŸ
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            from src.trading.services.grpc_trade_client import get_grpc_client, is_grpc_available
            
            if not is_grpc_available():
                logger.warning("gRPCä¸å¯ç”¨ï¼Œè·³è¿‡MT5å†å²æ•°æ®åˆå§‹åŒ–")
                return False
            
            logger.info(f"ğŸš€ å¼€å§‹ä»MT5æ‹‰å–å†å²Kçº¿æ•°æ®: {self.symbol} {timeframe} x {count}")
            
            client = get_grpc_client()
            client.timeout = 10  # 10ç§’è¶…æ—¶
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            try:
                import pytz
                timezone = pytz.timezone("Etc/UTC")
                to_dt = datetime.now(timezone)
            except ImportError:
                # å¦‚æœæ²¡æœ‰pytzï¼Œä½¿ç”¨UTCæ—¶é—´
                to_dt = datetime.utcnow()
            
            timeframe_minutes = {
                '1m': 1, '5m': 5, '15m': 15, '30m': 30,
                '1h': 60, '4h': 240, '1d': 1440
            }
            minutes_per_kline = timeframe_minutes.get(timeframe, 1)
            from_dt = to_dt - timedelta(minutes=count * minutes_per_kline)
            
            to_time = int(to_dt.timestamp())
            from_time = int(from_dt.timestamp())
            
            result = client.get_klines(
                symbol=self.symbol,
                timeframe=timeframe,
                from_time=from_time,
                to_time=to_time,
                count=count
            )
            
            if result.get('success') and result.get('klines'):
                mt5_klines = result['klines']
                logger.info(f"âœ“ ä»MT5è·å–åˆ° {len(mt5_klines)} æ ¹å†å²Kçº¿")
                
                # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                klines = []
                for k in mt5_klines:
                    klines.append({
                        'time': int(k['time']),
                        'open': float(k['open']),
                        'high': float(k['high']),
                        'low': float(k['low']),
                        'close': float(k['close']),
                        'volume': int(k.get('volume', k.get('tick_volume', 0))),
                        'real_volume': int(k.get('real_volume', 0))
                    })
                
                # 1. å»é‡
                unique_klines = self.deduplicate_klines(klines)
                
                # 2. æŒ‰æ—¶é—´æ’åº
                unique_klines.sort(key=lambda x: x.get('time', 0))
                
                # 3. è¡¥ç©º
                filled_klines = self.fill_missing_klines(unique_klines, timeframe)
                
                # 4. å­˜å‚¨åˆ°Redisï¼ˆåŸå­æ“ä½œï¼‰
                self._store_klines_atomic(filled_klines)
                
                logger.info(f"âœ… å†å²æ•°æ®åˆå§‹åŒ–å®Œæˆ: åŸå§‹={len(klines)}, å»é‡å={len(unique_klines)}, è¡¥ç©ºå={len(filled_klines)}")
                return True
            else:
                logger.warning(f"ä»MT5è·å–å†å²æ•°æ®å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return False
                
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å†å²æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return False
    
    def _store_klines_atomic(self, klines: List[Dict[str, Any]]):
        """
        åŸå­å­˜å‚¨Kçº¿æ•°æ®ï¼ˆä½¿ç”¨ä¸´æ—¶é”®+RENAMEï¼‰
        
        Args:
            klines: Kçº¿åˆ—è¡¨
        """
        temp_key = self.kline_key + ":temp"
        
        pipe = self.redis_client.pipeline()
        pipe.delete(temp_key)
        
        # æ‰¹é‡æ·»åŠ 
        zadd_map = {
            json.dumps(kline, ensure_ascii=False): kline.get('time', 0)
            for kline in klines
        }
        
        if zadd_map:
            pipe.zadd(temp_key, zadd_map)
        
        # åŸå­æ›¿æ¢
        pipe.rename(temp_key, self.kline_key)
        pipe.execute()
    
    def check_and_repair_recent(self, recent_count: int = 100, timeframe: str = '1m') -> Dict[str, Any]:
        """
        æ£€æŸ¥å¹¶ä¿®å¤æœ€è¿‘çš„Kçº¿æ•°æ®ï¼ˆå¢é‡ä¿®å¤ï¼Œè¡Œä¸šæœ€ä½³å®è·µï¼‰
        
        ã€ç­–ç•¥ã€‘
        - åªæ£€æŸ¥æœ€è¿‘Næ ¹Kçº¿ï¼ˆé»˜è®¤100æ ¹ï¼‰
        - å†å²æ•°æ®è§†ä¸ºå›ºå®šï¼Œä¸ä¿®æ”¹
        - è‡ªåŠ¨ä¿®å¤ç¼ºå¤±å’Œé‡å¤
        
        Args:
            recent_count: æ£€æŸ¥æœ€è¿‘Næ ¹Kçº¿
            timeframe: æ—¶é—´å‘¨æœŸ
            
        Returns:
            ä¿®å¤ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # ä»Redisè¯»å–æœ€è¿‘Næ ¹Kçº¿
            klines_json = self.redis_client.zrange(
                self.kline_key, -recent_count, -1, withscores=False
            )
            
            if not klines_json:
                return {'success': False, 'message': 'æ²¡æœ‰Kçº¿æ•°æ®'}
            
            # è§£æKçº¿æ•°æ®
            klines = [json.loads(k) for k in klines_json]
            original_count = len(klines)
            
            # 1. å»é‡
            unique_klines = self.deduplicate_klines(klines)
            
            # 2. æŒ‰æ—¶é—´æ’åº
            unique_klines.sort(key=lambda x: x.get('time', 0))
            
            # 3. æ£€æŸ¥æ—¶é—´é—´éš”
            anomalies, missing_count = self.check_time_interval(unique_klines, timeframe)
            self.stats['invalid_intervals'] = len(anomalies)
            self.stats['missing_klines'] = missing_count
            
            # 4. è¡¥ç©º
            filled_klines = self.fill_missing_klines(unique_klines, timeframe)
            
            # 5. å¦‚æœæœ‰å˜åŒ–ï¼Œæ›´æ–°Redisï¼ˆåªæ›´æ–°æœ€è¿‘çš„æ•°æ®ï¼‰
            if len(filled_klines) != original_count or len(unique_klines) != original_count:
                # åˆ é™¤æœ€è¿‘çš„æ•°æ®
                if klines:
                    first_time = klines[0].get('time', 0)
                    last_time = klines[-1].get('time', 0)
                    if first_time > 0 and last_time > 0:
                        self.redis_client.zremrangebyscore(
                            self.kline_key, first_time, last_time
                        )
                
                # æ·»åŠ ä¿®å¤åçš„æ•°æ®
                for kline in filled_klines:
                    kline_json = json.dumps(kline, ensure_ascii=False)
                    kline_time = kline.get('time', 0)
                    self.redis_client.zadd(self.kline_key, {kline_json: kline_time})
                
                logger.info(f"âœ… æœ€è¿‘æ•°æ®ä¿®å¤å®Œæˆ: åŸå§‹={original_count}, å»é‡å={len(unique_klines)}, è¡¥ç©ºå={len(filled_klines)}")
            
            self.stats['total_klines'] = len(filled_klines)
            
            return {
                'success': True,
                'original_count': original_count,
                'unique_count': len(unique_klines),
                'filled_count': len(filled_klines),
                'missing_count': missing_count,
                'duplicate_count': self.stats['duplicate_klines'],
                'anomalies': len(anomalies)
            }
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥å¹¶ä¿®å¤æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {'success': False, 'error': str(e)}
    
    def get_quality_report(self) -> Dict[str, Any]:
        """
        è·å–æ•°æ®è´¨é‡æŠ¥å‘Š
        
        Returns:
            æ•°æ®è´¨é‡ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            total_count = self.redis_client.zcard(self.kline_key)
            
            if total_count == 0:
                return {
                    'total_count': 0,
                    'status': 'empty',
                    'message': 'æ²¡æœ‰Kçº¿æ•°æ®'
                }
            
            # æ£€æŸ¥æœ€è¿‘100æ ¹Kçº¿
            recent_report = self.check_and_repair_recent(recent_count=100)
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            missing_rate = (self.stats['missing_klines'] / max(total_count, 1)) * 100
            duplicate_rate = (self.stats['duplicate_klines'] / max(total_count, 1)) * 100
            
            quality_score = 100 - missing_rate - duplicate_rate - (len(recent_report.get('anomalies', [])) * 0.1)
            quality_score = max(0, min(100, quality_score))
            
            return {
                'total_count': total_count,
                'missing_count': self.stats['missing_klines'],
                'duplicate_count': self.stats['duplicate_klines'],
                'filled_count': self.stats['filled_klines'],
                'invalid_intervals': self.stats['invalid_intervals'],
                'missing_rate': round(missing_rate, 2),
                'duplicate_rate': round(duplicate_rate, 2),
                'quality_score': round(quality_score, 2),
                'status': 'good' if quality_score >= 95 else 'warning' if quality_score >= 80 else 'poor',
                'recent_report': recent_report
            }
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®è´¨é‡æŠ¥å‘Šå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}


def initialize_data_on_startup(symbol: str = "BTCUSDm", count: int = 2880) -> bool:
    """
    å¯åŠ¨æ—¶æ•°æ®åˆå§‹åŒ–ï¼ˆè¡Œä¸šæœ€ä½³å®è·µï¼šåç«¯å¯åŠ¨æ—¶è‡ªåŠ¨è°ƒç”¨ï¼‰
    
    Args:
        symbol: äº¤æ˜“å“ç§
        count: æ‹‰å–æ•°é‡
        
    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    checker = DataIntegrityChecker(symbol)
    
    # æ£€æŸ¥Redisä¸­æ˜¯å¦å·²æœ‰æ•°æ®
    existing_count = checker.redis_client.zcard(checker.kline_key)
    
    if existing_count == 0:
        logger.info("Redisä¸­æ²¡æœ‰Kçº¿æ•°æ®ï¼Œå¼€å§‹ä»MT5åˆå§‹åŒ–...")
        success = checker.initialize_from_mt5(count=count)
        if success:
            logger.info("âœ… å¯åŠ¨æ—¶æ•°æ®åˆå§‹åŒ–æˆåŠŸ")
            return True
        else:
            logger.warning("âš ï¸ å¯åŠ¨æ—¶æ•°æ®åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å®æ—¶æ•°æ®æ„å»º")
            return False
    else:
        logger.info(f"Redisä¸­å·²æœ‰{existing_count}æ ¹Kçº¿ï¼Œè·³è¿‡åˆå§‹åŒ–")
        
        # æ£€æŸ¥å¹¶ä¿®å¤æœ€è¿‘çš„æ•°æ®
        report = checker.check_and_repair_recent(recent_count=100)
        if report.get('success'):
            logger.info(f"âœ… æœ€è¿‘æ•°æ®æ£€æŸ¥å®Œæˆ: {report}")
        
        return True  # å·²æœ‰æ•°æ®ï¼Œè§†ä¸ºæˆåŠŸ

