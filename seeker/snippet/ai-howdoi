#date: 2023-11-21T17:03:43Z
#url: https://api.github.com/gists/637b2925e346f16fdf6651d72db0432e
#owner: https://api.github.com/users/tos-kamiya

#!/usr/bin/env python3

import os
import subprocess
import sys


_llama_cpp_dir = "/path/to/llama.cpp/directory"
_model_file = "phind-codellama-34b-v2.Q4_K_M.gguf"

__doc__ = """Ask a programming question to Phind-CodeLlama-34b-v2.

Usage:
  codellama-howdoi
  codellama-howdoi -
  codellama-howdoi text...
"""

if len(sys.argv) < 2:
    print("Input question text (empty line to end): ")
    r = []
    while True:
        t = input("> ")
        if t == "":
            break
        r.append(t)
    text = "\n".join(r)
elif sys.argv[1] in ["-h", "--help"]:
    print(__doc__)
    exit()
elif sys.argv[1:] == ["-"]:
    text = sys.stdin.read()
else:
    text = " ".join(sys.argv[1:])

text = text.strip()
if not text:
    exit("Error: no question")

prompt = f"""
### System Prompt
You are an expert programmer that writes simple, concise code and explanations.

### User Message
{text}

### Assistant
"""

model = os.path.join("models", _model_file)
llama_exe = os.path.join(os.curdir, "main")

cmd = [llama_exe, "-m", model, "-p", prompt]
print(cmd)
# cmd = [llama_exe, "--help"]
subprocess.check_call(cmd, cwd=_llama_cpp_dir)
