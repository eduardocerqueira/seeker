#date: 2025-11-13T17:02:59Z
#url: https://api.github.com/gists/c1c2c32c02ad6b73f59da7fc63add2f0
#owner: https://api.github.com/users/wangwei334455

"""
æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æœåŠ¡

ã€èŒè´£åˆ†ç¦»ã€‘
- ä¸“é—¨è´Ÿè´£æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ã€å»é‡ã€è¡¥ç©º
- ç­–ç•¥æ ¸å¿ƒåªå¤„ç†å·²éªŒè¯çš„å®Œæ•´æ•°æ®
- API Serverä»å·²éªŒè¯çš„æ•°æ®ä¸­è¯»å–

ã€åŠŸèƒ½ã€‘
1. TICKæ•°æ®éªŒè¯ï¼ˆseqæ£€æŸ¥ã€checksuméªŒè¯ï¼‰
2. Kçº¿æ•°æ®å»é‡ï¼ˆç›¸åŒæ—¶é—´æˆ³åªä¿ç•™æœ€æ–°ï¼‰
3. Kçº¿æ•°æ®è¡¥ç©ºï¼ˆå¡«å……ç¼ºå¤±çš„æ—¶é—´æ®µï¼‰
4. æ•°æ®è´¨é‡ç›‘æ§ï¼ˆç¼ºå¤±ç‡ã€é‡å¤ç‡ç»Ÿè®¡ï¼‰
"""
import json
import time
import hashlib
import threading
from typing import Dict, Any, List, Optional
from datetime import datetime
from loguru import logger
import redis
import numpy as np

from config.redis_config import REDIS_CONFIG, REDIS_KEYS


class DataIntegrityService:
    """
    æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æœåŠ¡
    
    ã€æ¶æ„è®¾è®¡ã€‘
    - ç‹¬ç«‹æœåŠ¡ï¼Œä¸ä¾èµ–ç­–ç•¥æ ¸å¿ƒ
    - ç›‘å¬Redis Streamï¼ŒéªŒè¯TICKæ•°æ®
    - éªŒè¯åçš„æ•°æ®å­˜å‚¨åˆ°å·²éªŒè¯çš„Stream
    - å®šæœŸæ£€æŸ¥Kçº¿æ•°æ®å®Œæ•´æ€§ï¼Œè‡ªåŠ¨è¡¥ç©º
    """
    
    def __init__(self, symbol: str = "BTCUSDm"):
        self.symbol = symbol
        self.redis_client = redis.Redis(**REDIS_CONFIG)
        self.r_text = redis.Redis(
            host=REDIS_CONFIG.get('host', 'localhost'),
            port=REDIS_CONFIG.get('port', 6379),
            db=REDIS_CONFIG.get('db', 0),
            decode_responses=True
        )
        
        # Redis Keys
        self.tick_stream_key = REDIS_KEYS['tick_stream']  # åŸå§‹TICKæµ
        self.validated_tick_stream_key = f"tick:{symbol}:validated:stream"  # éªŒè¯åçš„TICKæµ
        self.kline_key = f"kline:{symbol}:1m"  # Kçº¿æ•°æ®
        
        # çŠ¶æ€
        self.last_processed_seq = 0
        self.stop_event = threading.Event()
        self.stats = {
            'ticks_validated': 0,
            'ticks_rejected': 0,
            'klines_deduplicated': 0,
            'klines_filled': 0,
        }
        
        logger.info(f"æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æœåŠ¡åˆå§‹åŒ–: {symbol}")
    
    def validate_tick(self, tick_data: Dict[str, Any]) -> bool:
        """
        éªŒè¯TICKæ•°æ®å®Œæ•´æ€§
        
        Args:
            tick_data: TICKæ•°æ®å­—å…¸
            
        Returns:
            bool: æ˜¯å¦é€šè¿‡éªŒè¯
        """
        try:
            # 1. æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['time_msc', 'seq', 'checksum', 'last', 'bid', 'ask']
            if not all(field in tick_data for field in required_fields):
                logger.warning(f"TICKç¼ºå°‘å¿…éœ€å­—æ®µ: {tick_data}")
                return False
            
            # 2. æ£€æŸ¥åºåˆ—å·ï¼ˆSeq Checkï¼‰
            current_seq = tick_data.get('seq', 0)
            expected_seq = self.last_processed_seq + 1
            
            # å¤„ç†é¦–æ¬¡TICKï¼ˆseq=0ï¼‰
            if current_seq == 0 and self.last_processed_seq == 0:
                current_seq = 1
                tick_data['seq'] = 1
            
            # å¤„ç†seqè·³è·ƒï¼ˆå…è®¸ç»§ç»­ï¼Œä½†è®°å½•è­¦å‘Šï¼‰
            if current_seq > expected_seq:
                seq_gap = current_seq - expected_seq
                # ğŸ”´ ä¼˜åŒ–ï¼šå°å¹…åº¦è·³è·ƒï¼ˆ<10ï¼‰å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼ˆæœåŠ¡é‡å¯ï¼‰ï¼Œåªè®°å½•DEBUG
                # å¤§å¹…åº¦è·³è·ƒï¼ˆ>=10ï¼‰æ‰è®°å½•WARNINGï¼Œå¯èƒ½æ˜¯æ•°æ®ä¸¢å¤±
                if seq_gap < 10:
                    logger.debug(f"æ•°æ®å®Œæ•´æ€§: Seqå°å¹…è·³è·ƒï¼ˆå¯èƒ½æœåŠ¡é‡å¯ï¼‰ - æœŸæœ› {expected_seq}ï¼Œå®é™…æ”¶åˆ° {current_seq}ï¼ˆè·³è·ƒ {seq_gap}ï¼‰")
                else:
                    logger.warning(f"æ•°æ®å®Œæ•´æ€§: Seqå¤§å¹…è·³è·ƒï¼æœŸæœ› {expected_seq}ï¼Œå®é™…æ”¶åˆ° {current_seq}ï¼ˆä¸¢å¤±äº† {seq_gap} ä¸ªTICKï¼‰")
                self.last_processed_seq = current_seq - 1
                expected_seq = current_seq
            
            # å¤„ç†é‡å¤seqï¼ˆè·³è¿‡ï¼Œä½†é™ä½æ—¥å¿—çº§åˆ«ï¼Œé¿å…æ—¥å¿—åˆ·å±ï¼‰
            if current_seq < expected_seq:
                # ğŸ”´ ä¿®å¤ï¼šåªåœ¨seqå·®è·è¾ƒå¤§æ—¶è®°å½•è­¦å‘Šï¼Œé¿å…æ—¥å¿—åˆ·å±
                if expected_seq - current_seq > 10:
                    logger.warning(f"æ•°æ®å®Œæ•´æ€§: Seqé‡å¤ï¼æœŸæœ› {expected_seq}ï¼Œå®é™…æ”¶åˆ° {current_seq}ï¼ˆå·®è· {expected_seq - current_seq}ï¼Œè·³è¿‡ï¼‰")
                # å¦åˆ™é™é»˜è·³è¿‡ï¼Œä¸è®°å½•æ—¥å¿—
                return False
            
            # 3. æ ¡éªŒå’ŒéªŒè¯ï¼ˆChecksum Checkï¼‰
            checksum_base = f"{tick_data.get('time_msc', 0)}:{current_seq}:{tick_data.get('bid', 0)}:{tick_data.get('ask', 0)}"
            recalculated_checksum = hashlib.md5(checksum_base.encode('utf-8')).hexdigest()[:8]
            
            if recalculated_checksum != tick_data.get('checksum', ''):
                logger.error(f"æ•°æ®å®Œæ•´æ€§: Checksumé”™è¯¯ï¼Seq={current_seq}ã€‚æ•°æ®å¯èƒ½è¢«ç¯¡æ”¹ï¼")
                return False
            
            # 4. æ›´æ–°æœ€åå¤„ç†çš„seq
            self.last_processed_seq = current_seq
            self.stats['ticks_validated'] += 1
            
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®å®Œæ•´æ€§: TICKéªŒè¯å¼‚å¸¸: {e}")
            return False
    
    def deduplicate_klines(self, klines: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å»é‡Kçº¿æ•°æ®ï¼ˆç›¸åŒæ—¶é—´æˆ³åªä¿ç•™æœ€æ–°çš„ï¼‰
        
        Args:
            klines: Kçº¿åˆ—è¡¨
            
        Returns:
            å»é‡åçš„Kçº¿åˆ—è¡¨
        """
        seen_times = {}
        for kline in klines:
            kline_time = kline.get('time', 0)
            if kline_time > 0:
                # ä¿ç•™æœ€æ–°çš„æ•°æ®ï¼ˆåé¢çš„æ•°æ®è¦†ç›–å‰é¢çš„ï¼‰
                if kline_time not in seen_times:
                    seen_times[kline_time] = kline
                else:
                    # å¦‚æœvolumeæ›´å¤§ï¼Œè¯´æ˜æ˜¯æ›´å®Œæ•´çš„æ•°æ®
                    if kline.get('volume', 0) > seen_times[kline_time].get('volume', 0):
                        seen_times[kline_time] = kline
                        self.stats['klines_deduplicated'] += 1
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ—¶é—´æ’åº
        unique_klines = list(seen_times.values())
        unique_klines.sort(key=lambda x: x.get('time', 0))
        
        return unique_klines
    
    def fill_missing_klines(self, klines: List[Dict[str, Any]], timeframe: str = '1m') -> List[Dict[str, Any]]:
        """
        å¡«å……ç¼ºå¤±çš„Kçº¿ï¼ˆMT5å®˜æ–¹æœ€ä½³å®è·µï¼‰
        
        Args:
            klines: Kçº¿åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
            timeframe: æ—¶é—´å‘¨æœŸï¼ˆ'1m', '5m'ç­‰ï¼‰
            
        Returns:
            å¡«å……åçš„Kçº¿åˆ—è¡¨
        """
        if len(klines) < 2:
            return klines
        
        # æ—¶é—´å‘¨æœŸæ˜ å°„
        timeframe_minutes = {
            '1m': 1, '5m': 5, '15m': 15, '30m': 30,
            '1h': 60, '4h': 240, '1d': 1440
        }
        minutes_per_kline = timeframe_minutes.get(timeframe, 1)
        expected_interval = minutes_per_kline * 60  # ç§’
        
        filled_klines = [klines[0]]  # ç¬¬ä¸€æ ¹Kçº¿
        
        for i in range(1, len(klines)):
            prev_kline = klines[i - 1]
            current_kline = klines[i]
            
            prev_time = prev_kline.get('time', 0)
            current_time = current_kline.get('time', 0)
            
            # è®¡ç®—å®é™…æ—¶é—´é—´éš”
            actual_interval = current_time - prev_time
            
            # å¦‚æœæ—¶é—´é—´éš”å¤§äºæœŸæœ›é—´éš”ï¼Œè¯´æ˜æœ‰ç¼ºå¤±
            if actual_interval > expected_interval + 1:  # å…è®¸1ç§’å®¹å·®
                # ğŸ”´ ä¿®å¤ï¼šæ›´ç²¾ç¡®çš„ç¼ºå¤±Kçº¿æ•°é‡è®¡ç®—
                # è®¡ç®—ç†è®ºä¸Šåº”è¯¥æœ‰çš„Kçº¿æ•°é‡ï¼Œå¹¶å‡å»å·²æœ‰çš„1æ ¹ï¼ˆå½“å‰Kçº¿ï¼‰
                # ä¾‹å¦‚ï¼šé—´éš”120sï¼ŒæœŸæœ›60sï¼Œåº”è¯¥æœ‰2æ ¹ï¼Œç¼ºå¤±1æ ¹
                # ä¾‹å¦‚ï¼šé—´éš”180sï¼ŒæœŸæœ›60sï¼Œåº”è¯¥æœ‰3æ ¹ï¼Œç¼ºå¤±2æ ¹
                kline_count_in_gap = actual_interval // expected_interval
                missing_count = kline_count_in_gap - 1  # åº”è¯¥æœ‰çš„æ•°é‡ - 1 (å½“å‰Kçº¿)
                
                if missing_count >= 1:
                    logger.debug(f"æ•°æ®å®Œæ•´æ€§: å‘ç°Kçº¿ç¼ºå¤± - ä» {prev_time} åˆ° {current_time} ç¼ºå¤± {missing_count} æ ¹ (é—´éš”={actual_interval}s, æœŸæœ›={expected_interval}s)")
                    
                    # å¡«å……ç¼ºå¤±çš„Kçº¿
                    prev_close = prev_kline.get('close', 0)
                    if prev_close > 0:
                        for j in range(1, missing_count + 1):
                            missing_time = prev_time + (j * expected_interval)
                            
                            filled_kline = {
                                'time': missing_time,
                                'open': prev_close,
                                'high': prev_close,
                                'low': prev_close,
                                'close': prev_close,
                                'volume': 0,
                                'real_volume': 0,
                                'is_filled': True
                            }
                            filled_klines.append(filled_kline)
                            self.stats['klines_filled'] += 1
                    else:
                        logger.warning(f"æ•°æ®å®Œæ•´æ€§: æ— æ³•å¡«å……ç¼ºå¤±Kçº¿ - å‰ä¸€æ ¹æ”¶ç›˜ä»·ä¸º0, time={prev_time}")
            
            # æ·»åŠ å½“å‰Kçº¿
            filled_klines.append(current_kline)
        
        return filled_klines
    
    def validate_and_store_tick(self, tick_data: Dict[str, Any]):
        """
        éªŒè¯TICKæ•°æ®å¹¶å­˜å‚¨åˆ°å·²éªŒè¯çš„Stream
        
        Args:
            tick_data: TICKæ•°æ®å­—å…¸
        """
        if self.validate_tick(tick_data):
            # å­˜å‚¨åˆ°éªŒè¯åçš„Streamï¼ˆä¾›ç­–ç•¥æ ¸å¿ƒæ¶ˆè´¹ï¼‰
            tick_json = json.dumps(tick_data, ensure_ascii=False)
            self.r_text.xadd(
                self.validated_tick_stream_key,
                {'value': tick_json},
                id='*',
                maxlen=1000,
                approximate=True
            )
        else:
            self.stats['ticks_rejected'] += 1
    
    def check_and_fix_klines(self):
        """
        æ£€æŸ¥å¹¶ä¿®å¤Kçº¿æ•°æ®å®Œæ•´æ€§ï¼ˆå®šæœŸæ‰§è¡Œï¼‰
        
        ã€èŒè´£ã€‘
        - å®šæœŸæ£€æŸ¥Redisä¸­çš„Kçº¿æ•°æ®å®Œæ•´æ€§
        - å»é‡ï¼ˆç›¸åŒæ—¶é—´æˆ³åªä¿ç•™æœ€æ–°ï¼‰
        - è¡¥ç©ºï¼ˆå¡«å……ç¼ºå¤±çš„æ—¶é—´æ®µï¼‰
        
        ã€æ³¨æ„ã€‘
        - L2ç­–ç•¥æ ¸å¿ƒåœ¨å­˜å‚¨æ—¶å·²ç»å»é‡ï¼ˆä½¿ç”¨zremrangebyscoreï¼‰
        - API Serveråœ¨è¯»å–æ—¶ä¹Ÿä¼šå»é‡å’Œè¡¥ç©º
        - æ­¤æ–¹æ³•ä½œä¸ºæœ€åçš„ä¿éšœï¼Œå®šæœŸä¿®å¤å†å²æ•°æ®
        
        åŠŸèƒ½ï¼š
        1. å»é‡ï¼ˆç›¸åŒæ—¶é—´æˆ³åªä¿ç•™æœ€æ–°ï¼‰
        2. è¡¥ç©ºï¼ˆå¡«å……ç¼ºå¤±çš„æ—¶é—´æ®µï¼‰
        3. å­˜å‚¨ä¿®å¤åçš„æ•°æ®
        """
        try:
            # ä»Redisè¯»å–æ‰€æœ‰Kçº¿
            klines_json = self.r_text.zrange(self.kline_key, 0, -1, withscores=False)
            if not klines_json:
                return
            
            # è§£æKçº¿æ•°æ®
            klines = [json.loads(k) for k in klines_json]
            original_count = len(klines)
            
            # 1. å»é‡ï¼ˆä½¿ç”¨zremrangebyscoreç¡®ä¿æ—¶é—´æˆ³å”¯ä¸€ï¼‰
            unique_klines = []
            seen_times = set()
            for kline in klines:
                kline_time = kline.get('time', 0)
                if kline_time > 0 and kline_time not in seen_times:
                    unique_klines.append(kline)
                    seen_times.add(kline_time)
                elif kline_time in seen_times:
                    # å‘ç°é‡å¤ï¼Œéœ€è¦å»é‡
                    self.stats['klines_deduplicated'] += 1
            
            # æŒ‰æ—¶é—´æ’åº
            unique_klines.sort(key=lambda x: x.get('time', 0))
            
            # 2. è¡¥ç©ºï¼ˆå¡«å……ç¼ºå¤±çš„æ—¶é—´æ®µï¼‰
            filled_klines = self.fill_missing_klines(unique_klines, '1m')
            
            # 3. å¦‚æœæ•°æ®æœ‰å˜åŒ–ï¼Œé‡æ–°å­˜å‚¨åˆ°Redisï¼ˆä½¿ç”¨åŸå­æ“ä½œï¼‰
            if len(filled_klines) != original_count or len(unique_klines) != original_count:
                # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨ä¸´æ—¶é”®å’Œ RENAME å®ç°åŸå­æ›¿æ¢
                # é¿å…åœ¨ä¿®å¤è¿‡ç¨‹ä¸­ API Server è¯»åˆ°ç©ºæ•°æ®
                temp_kline_key = self.kline_key + ":temp"
                
                # ä½¿ç”¨pipelineæ‰¹é‡æ“ä½œï¼Œç¡®ä¿åŸå­æ€§
                pipe = self.r_text.pipeline()
                
                # æ¸…ç©ºä¸´æ—¶ ZSETï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                pipe.delete(temp_kline_key)
                
                # æ‰¹é‡æ·»åŠ ä¿®å¤åçš„Kçº¿åˆ°ä¸´æ—¶ ZSET
                zadd_map = {
                    json.dumps(kline, ensure_ascii=False): kline.get('time', 0)
                    for kline in filled_klines
                }
                
                # ZADD æ‰¹é‡å†™å…¥
                if zadd_map:
                    pipe.zadd(temp_kline_key, zadd_map)
                
                # åŸå­æ›¿æ¢ï¼šå°†ä¸´æ—¶ ZSET é‡å‘½åä¸ºæ­£å¼ ZSET
                # RENAME æ˜¯åŸå­æ“ä½œï¼Œç¡®ä¿ API Server ä¸ä¼šè¯»åˆ°ç©ºæ•°æ®
                pipe.rename(temp_kline_key, self.kline_key)
                
                # æ‰§è¡Œæ‰¹é‡æ“ä½œ
                pipe.execute()
                
                logger.info(f"æ•°æ®å®Œæ•´æ€§: Kçº¿æ•°æ®å·²ä¿®å¤ï¼ˆåŸå­æ›¿æ¢ï¼‰ - åŸå§‹:{original_count}, å»é‡å:{len(unique_klines)}, è¡¥ç©ºå:{len(filled_klines)}")
            else:
                logger.debug(f"æ•°æ®å®Œæ•´æ€§: Kçº¿æ•°æ®æ£€æŸ¥å®Œæˆï¼Œæ— éœ€ä¿®å¤ - {original_count}æ ¹Kçº¿")
            
        except Exception as e:
            logger.error(f"æ•°æ®å®Œæ•´æ€§: æ£€æŸ¥Kçº¿æ•°æ®å¤±è´¥: {e}")
    
    def run_tick_validator(self):
        """
        è¿è¡ŒTICKéªŒè¯å™¨ï¼ˆç›‘å¬åŸå§‹TICKæµï¼ŒéªŒè¯åå­˜å‚¨åˆ°å·²éªŒè¯æµï¼‰
        
        ã€æ•°æ®æµã€‘
        - è¾“å…¥: Redis Stream (tick:BTCUSDm:stream) - åŸå§‹TICKæµï¼ˆData Pullerå†™å…¥ï¼‰
        - è¾“å‡º: Redis Stream (tick:BTCUSDm:validated:stream) - éªŒè¯åçš„TICKæµï¼ˆL2ç­–ç•¥æ ¸å¿ƒæ¶ˆè´¹ï¼‰
        
        ã€éªŒè¯é€»è¾‘ã€‘
        1. Seqé¡ºåºæ£€æŸ¥ï¼šç¡®ä¿TICKæŒ‰é¡ºåºæ¥æ”¶
        2. ChecksuméªŒè¯ï¼šç¡®ä¿æ•°æ®æœªè¢«ç¯¡æ”¹
        3. éªŒè¯é€šè¿‡åæ¨é€åˆ°å·²éªŒè¯æµ
        """
        logger.info("æ•°æ®å®Œæ•´æ€§: TICKéªŒè¯å™¨å·²å¯åŠ¨")
        logger.info(f"  - ç›‘å¬åŸå§‹æµ: {self.tick_stream_key}")
        logger.info(f"  - è¾“å‡ºå·²éªŒè¯æµ: {self.validated_tick_stream_key}")
        # ğŸ”´ ä¿®å¤ï¼šä»æµçš„æœ«å°¾å¼€å§‹è¯»å–ï¼ˆåªå¤„ç†æ–°æ•°æ®ï¼‰ï¼Œé¿å…å¤„ç†å†å²æ•°æ®å¯¼è‡´Seqé‡å¤
        # ä½¿ç”¨ '$' è¡¨ç¤ºåªè¯»å–æ–°æ¶ˆæ¯ï¼Œé¿å…å¤„ç†å†å²æ•°æ®
        last_id = '$'
        reconnect_delay = 1.0
        
        while not self.stop_event.is_set():
            try:
                # ç¡®ä¿Redisè¿æ¥
                try:
                    self.r_text.ping()
                except (redis.exceptions.ConnectionError, redis.exceptions.TimeoutError):
                    logger.warning(f"æ•°æ®å®Œæ•´æ€§: Redisè¿æ¥ä¸¢å¤±ï¼Œ{reconnect_delay}ç§’åé‡è¯•...")
                    time.sleep(reconnect_delay)
                    reconnect_delay = min(reconnect_delay * 2, 10.0)
                    # å°è¯•é‡æ–°åˆ›å»ºè¿æ¥
                    try:
                        self.r_text = redis.Redis(
                            host=REDIS_CONFIG.get('host', 'localhost'),
                            port=REDIS_CONFIG.get('port', 6379),
                            db=REDIS_CONFIG.get('db', 0),
                            decode_responses=True
                        )
                        self.r_text.ping()
                        reconnect_delay = 1.0
                        logger.info("æ•°æ®å®Œæ•´æ€§: Redisè¿æ¥å·²æ¢å¤")
                    except:
                        logger.warning("æ•°æ®å®Œæ•´æ€§: Redisè¿æ¥ä»æœªæ¢å¤ï¼Œç»§ç»­ç­‰å¾…...")
                        continue
                
                # ä»åŸå§‹TICKæµè¯»å–ï¼ˆé˜»å¡è¯»å–ï¼Œè¶…æ—¶100msï¼‰
                messages = self.r_text.xread({self.tick_stream_key: last_id}, count=10, block=100)
                
                if not messages:
                    continue
                
                # å¤„ç†æ¶ˆæ¯
                for stream, msgs in messages:
                    for msg_id, msg_data in msgs:
                        try:
                            # è§£æTICKæ•°æ®ï¼ˆData Pullerå†™å…¥æ ¼å¼ï¼š{'value': json_string}ï¼‰
                            tick_json = msg_data.get('value', '')
                            if tick_json:
                                tick_data = json.loads(tick_json)
                                # éªŒè¯å¹¶å­˜å‚¨åˆ°å·²éªŒè¯æµ
                                self.validate_and_store_tick(tick_data)
                            else:
                                logger.warning(f"æ•°æ®å®Œæ•´æ€§: TICKæ•°æ®ç¼ºå°‘'value'å­—æ®µ: {msg_data}")
                        except json.JSONDecodeError as e:
                            logger.error(f"æ•°æ®å®Œæ•´æ€§: TICK JSONè§£æå¤±è´¥: {e}, æ•°æ®: {msg_data}")
                        except Exception as e:
                            logger.error(f"æ•°æ®å®Œæ•´æ€§: å¤„ç†TICKå¤±è´¥: {e}")
                        
                        last_id = msg_id
                
            except redis.exceptions.ConnectionError as ce:
                logger.warning(f"æ•°æ®å®Œæ•´æ€§: Redisè¿æ¥é”™è¯¯: {ce}")
                time.sleep(reconnect_delay)
                reconnect_delay = min(reconnect_delay * 2, 10.0)
            except Exception as e:
                logger.error(f"æ•°æ®å®Œæ•´æ€§: TICKéªŒè¯å™¨å¼‚å¸¸: {e}")
                time.sleep(1)
    
    def run_kline_checker(self):
        """
        è¿è¡ŒKçº¿æ£€æŸ¥å™¨ï¼ˆå®šæœŸæ£€æŸ¥å¹¶ä¿®å¤Kçº¿æ•°æ®ï¼‰
        
        ã€è¡Œä¸šæœ€ä½³å®è·µã€‘
        - å®šæœŸæ£€æŸ¥æœ€è¿‘Næ ¹Kçº¿ï¼ˆå¢é‡ä¿®å¤ï¼‰
        - å†å²æ•°æ®è§†ä¸ºå›ºå®šï¼Œä¸ä¿®æ”¹
        - è‡ªåŠ¨ä¿®å¤ç¼ºå¤±å’Œé‡å¤
        """
        logger.info("æ•°æ®å®Œæ•´æ€§: Kçº¿æ£€æŸ¥å™¨å·²å¯åŠ¨")
        
        # ğŸš€ å¯åŠ¨æ—¶ç«‹å³æ£€æŸ¥ä¸€æ¬¡
        try:
            from src.trading.services.data_integrity_checker import DataIntegrityChecker
            checker = DataIntegrityChecker(symbol=self.symbol)
            report = checker.check_and_repair_recent(recent_count=100)
            if report.get('success'):
                logger.info(f"æ•°æ®å®Œæ•´æ€§: å¯åŠ¨æ—¶æ£€æŸ¥å®Œæˆ - {report}")
        except Exception as e:
            logger.warning(f"æ•°æ®å®Œæ•´æ€§: å¯åŠ¨æ—¶æ£€æŸ¥å¤±è´¥: {e}")
        
        while not self.stop_event.is_set():
            try:
                # æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ï¼ˆå¢é‡ä¿®å¤æœ€è¿‘100æ ¹ï¼‰
                self.stop_event.wait(300)
                
                if not self.stop_event.is_set():
                    self.check_and_fix_klines()
                    
                    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                    logger.info(f"æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡: TICKå·²éªŒè¯={self.stats['ticks_validated']}, "
                              f"TICKæ‹’ç»={self.stats['ticks_rejected']}, "
                              f"Kçº¿å»é‡={self.stats['klines_deduplicated']}, "
                              f"Kçº¿è¡¥ç©º={self.stats['klines_filled']}")
                    
            except Exception as e:
                logger.error(f"æ•°æ®å®Œæ•´æ€§: Kçº¿æ£€æŸ¥å™¨å¼‚å¸¸: {e}")
    
    def start(self):
        """å¯åŠ¨æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æœåŠ¡"""
        logger.info("=" * 70)
        logger.info("æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æœåŠ¡å¯åŠ¨")
        logger.info("=" * 70)
        
        # å¯åŠ¨TICKéªŒè¯å™¨çº¿ç¨‹
        tick_thread = threading.Thread(target=self.run_tick_validator, daemon=True, name="TickValidator")
        tick_thread.start()
        
        # å¯åŠ¨Kçº¿æ£€æŸ¥å™¨çº¿ç¨‹
        kline_thread = threading.Thread(target=self.run_kline_checker, daemon=True, name="KlineChecker")
        kline_thread.start()
        
        logger.info("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æœåŠ¡å·²å¯åŠ¨")
        logger.info("  - TICKéªŒè¯å™¨: ç›‘å¬åŸå§‹TICKæµï¼ŒéªŒè¯åå­˜å‚¨åˆ°å·²éªŒè¯æµ")
        logger.info("  - Kçº¿æ£€æŸ¥å™¨: å®šæœŸæ£€æŸ¥å¹¶ä¿®å¤Kçº¿æ•°æ®ï¼ˆå»é‡ã€è¡¥ç©ºï¼‰")
    
    def stop(self):
        """åœæ­¢æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æœåŠ¡"""
        self.stop_event.set()
        logger.info("æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æœåŠ¡å·²åœæ­¢")

