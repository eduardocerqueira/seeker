#date: 2025-08-08T16:51:44Z
#url: https://api.github.com/gists/269ec86255cb8c6434929630db83c115
#owner: https://api.github.com/users/datavudeja

ï»¿import spacy
from spacy.training import Example
from spacy.util import minibatch, compounding
import random

nlp = spacy.load("en_core_web_sm")

# Train the model with custom entities for better recognition
ner = nlp.get_pipe("ner")
ner.add_label("DATA_FIELD")

TRAIN_DATA = [
    ("Users activity by week", {"entities": [(0, 5, "DATA_FIELD"), (14, 18, "DATA_FIELD")]}),
    ("Status report by quarter", {"entities": [(0, 6, "DATA_FIELD"), (16, 23, "DATA_FIELD")]}),
    # Add more examples here
]

other_pipes = [pipe for pipe in nlp.pipe_names if pipe != "ner"]
with nlp.disable_pipes(*other_pipes):  # only train NER
    optimizer = nlp.begin_training()
    for itn in range(10):
        random.shuffle(TRAIN_DATA)
        losses = {}
        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))
        for batch in batches:
            examples = [Example.from_dict(nlp.make_doc(text), annotations) for text, annotations in batch]
            nlp.update(examples, drop=0.5, sgd=optimizer, losses=losses)
        print("Losses", losses)

def parse_nlp_visualize(query):
    doc = nlp(query)
    visualization_type = None
    group_by = None
    filter_by = None
    conditions = []
    aggregation = None

 "**********"  "**********"  "**********"  "**********"  "**********"f "**********"o "**********"r "**********"  "**********"t "**********"o "**********"k "**********"e "**********"n "**********"  "**********"i "**********"n "**********"  "**********"d "**********"o "**********"c "**********": "**********"
 "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"i "**********"f "**********"  "**********"t "**********"o "**********"k "**********"e "**********"n "**********". "**********"t "**********"e "**********"x "**********"t "**********". "**********"l "**********"o "**********"w "**********"e "**********"r "**********"( "**********") "**********"  "**********"i "**********"n "**********"  "**********"[ "**********"" "**********"a "**********"c "**********"t "**********"i "**********"v "**********"i "**********"t "**********"y "**********"" "**********", "**********"  "**********"" "**********"h "**********"e "**********"a "**********"t "**********"m "**********"a "**********"p "**********"" "**********", "**********"  "**********"" "**********"f "**********"r "**********"e "**********"q "**********"u "**********"e "**********"n "**********"c "**********"y "**********"" "**********", "**********"  "**********"" "**********"s "**********"t "**********"a "**********"t "**********"u "**********"s "**********"" "**********"] "**********": "**********"
            visualization_type = "**********"
 "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"e "**********"l "**********"i "**********"f "**********"  "**********"t "**********"o "**********"k "**********"e "**********"n "**********". "**********"t "**********"e "**********"x "**********"t "**********". "**********"l "**********"o "**********"w "**********"e "**********"r "**********"( "**********") "**********"  "**********"i "**********"n "**********"  "**********"[ "**********"" "**********"b "**********"y "**********"" "**********", "**********"  "**********"" "**********"g "**********"r "**********"o "**********"u "**********"p "**********"" "**********"] "**********": "**********"
            next_token = "**********"
 "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"i "**********"f "**********"  "**********"n "**********"e "**********"x "**********"t "**********"_ "**********"t "**********"o "**********"k "**********"e "**********"n "**********": "**********"
                group_by = "**********"
                # Check for time scales
                if group_by in ["week", "month", "quarter", "year"]:
                    aggregation = group_by
 "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"e "**********"l "**********"i "**********"f "**********"  "**********"t "**********"o "**********"k "**********"e "**********"n "**********". "**********"t "**********"e "**********"x "**********"t "**********". "**********"l "**********"o "**********"w "**********"e "**********"r "**********"( "**********") "**********"  "**********"i "**********"n "**********"  "**********"[ "**********"" "**********"f "**********"i "**********"l "**********"t "**********"e "**********"r "**********"" "**********", "**********"  "**********"" "**********"w "**********"h "**********"e "**********"r "**********"e "**********"" "**********"] "**********": "**********"
            next_token = "**********"
 "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"i "**********"f "**********"  "**********"n "**********"e "**********"x "**********"t "**********"_ "**********"t "**********"o "**********"k "**********"e "**********"n "**********": "**********"
                filter_by = "**********"
 "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"e "**********"l "**********"i "**********"f "**********"  "**********"t "**********"o "**********"k "**********"e "**********"n "**********". "**********"t "**********"e "**********"x "**********"t "**********". "**********"l "**********"o "**********"w "**********"e "**********"r "**********"( "**********") "**********"  "**********"i "**********"n "**********"  "**********"[ "**********"" "**********"a "**********"n "**********"d "**********"" "**********", "**********"  "**********"" "**********"o "**********"r "**********"" "**********"] "**********": "**********"
            conditions.append(token.text.lower())
 "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"e "**********"l "**********"i "**********"f "**********"  "**********"t "**********"o "**********"k "**********"e "**********"n "**********". "**********"e "**********"n "**********"t "**********"_ "**********"t "**********"y "**********"p "**********"e "**********"_ "**********"  "**********"i "**********"n "**********"  "**********"[ "**********"" "**********"D "**********"A "**********"T "**********"E "**********"" "**********", "**********"  "**********"" "**********"T "**********"I "**********"M "**********"E "**********"" "**********", "**********"  "**********"" "**********"G "**********"P "**********"E "**********"" "**********", "**********"  "**********"" "**********"O "**********"R "**********"G "**********"" "**********", "**********"  "**********"" "**********"P "**********"E "**********"R "**********"S "**********"O "**********"N "**********"" "**********"] "**********"  "**********"o "**********"r "**********"  "**********"t "**********"o "**********"k "**********"e "**********"n "**********". "**********"e "**********"n "**********"t "**********"_ "**********"t "**********"y "**********"p "**********"e "**********"_ "**********"  "**********"= "**********"= "**********"  "**********"" "**********"D "**********"A "**********"T "**********"A "**********"_ "**********"F "**********"I "**********"E "**********"L "**********"D "**********"" "**********": "**********"
 "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"  "**********"c "**********"o "**********"n "**********"d "**********"i "**********"t "**********"i "**********"o "**********"n "**********"s "**********". "**********"a "**********"p "**********"p "**********"e "**********"n "**********"d "**********"( "**********"f "**********"" "**********"{ "**********"t "**********"o "**********"k "**********"e "**********"n "**********". "**********"e "**********"n "**********"t "**********"_ "**********"t "**********"y "**********"p "**********"e "**********"_ "**********". "**********"l "**********"o "**********"w "**********"e "**********"r "**********"( "**********") "**********"} "**********"  "**********"= "**********"= "**********"  "**********"' "**********"{ "**********"t "**********"o "**********"k "**********"e "**********"n "**********". "**********"t "**********"e "**********"x "**********"t "**********"} "**********"' "**********"" "**********") "**********"

    if not visualization_type:
        raise ValueError("No visualization type specified in the query.")
    if group_by is None:
        print("Warning: No grouping specified, using default visualization.")
    
    return {
        "visualization_type": visualization_type,
        "group_by": group_by,
        "filter_by": filter_by,
        "conditions": " ".join(conditions),
        "aggregation": aggregation
    }

# Example usage
if __name__ == "__main__":
    query = "Show activity heatmap by week where name is John and online"
    print(parse_nlp_visualize(query))