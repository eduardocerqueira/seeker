#date: 2023-07-17T17:07:20Z
#url: https://api.github.com/gists/ca0f763a8bc3c012a79862beed5bde43
#owner: https://api.github.com/users/relh

#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import shutil
from multiprocessing import Pool

import cv2
import numpy as np
from cv2 import KeyPoint

# Initialize SIFT detector
sift = cv2.SIFT_create()

# Set the match ratio
LOWE_RATIO = 0.75

# Set the directory where the frames are
frame_directory = '/path/to/your/frames/'
selected_frame_directory = frame_directory.replace('frames', 'selected_frames')
os.makedirs(selected_frame_directory, exist_ok=True)

# Load the frames
frames = sorted(os.listdir(frame_directory))

# Keep track of non-redundant frames
non_redundant_frames = []

def compute_sift_features(frame_path):
    print(frame_path)
    frame = cv2.imread(frame_path, cv2.IMREAD_GRAYSCALE)
    kp, des = sift.detectAndCompute(frame, None)
    kp = [np.array([k.pt[0], k.pt[1], k.size, k.angle, k.response, k.octave, k.class_id]) for k in kp]
    return kp, des

# Load the frame paths
frames = frame_paths = sorted([os.path.join(frame_directory, frame) for frame in os.listdir(frame_directory) if 'jpg' in frame])#[:50]

# Create a pool of processes
with Pool() as pool:
    # Compute SIFT features for each frame
    kp_des_pairs = pool.map(compute_sift_features, frame_paths)

i = 0
while i < len(frame_paths):
    #kp1, des1 = sift.detectAndCompute(frame1, None)
    kp1, des1 = kp_des_pairs[i]
    kp1 = [KeyPoint(x=kp[0], y=kp[1], size=kp[2], angle=kp[3], response=kp[4], octave=int(kp[5]), class_id=int(kp[6])) for kp in kp1]

    # Keep track of non-redundant frames
    non_redundant_frames.append(frames[i])

    # Iterate over subsequent frames
    for j in range(i + 1, len(frames)):
        # Load the subsequent frame
        frame2 = cv2.imread(os.path.join(frame_directory, frames[j]), cv2.IMREAD_GRAYSCALE)
        #kp2, des2 = sift.detectAndCompute(frame2, None)
        kp2, des2 = kp_des_pairs[j]
        kp2 = [KeyPoint(x=kp[0], y=kp[1], size=kp[2], angle=kp[3], response=kp[4], octave=int(kp[5]), class_id=int(kp[6])) for kp in kp2]

        # Match the descriptors using FLANN matcher
        FLANN_INDEX_KDTREE = 1
        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
        search_params = dict(checks=50)
        flann = cv2.FlannBasedMatcher(index_params, search_params)
        matches = flann.knnMatch(des1, des2, k=2)

        # Apply Lowe's ratio test to find good matches
        good = []
        for m, n in matches:
            if m.distance < LOWE_RATIO * n.distance:
                good.append(m)

        # Compute homography using RANSAC
        if len(good) > 4:
            src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
            H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
            if H is not None:

                # Load the reference frame
                frame1 = cv2.imread(os.path.join(frame_directory, frames[i]), cv2.IMREAD_GRAYSCALE)
                # Calculate the area of overlap
                height, width = frame1.shape
                warped_frame = cv2.warpPerspective(frame1, H, (width, height))
                frame2 = cv2.imread(frame_paths[j], cv2.IMREAD_GRAYSCALE)
                common_area = np.count_nonzero(warped_frame) + np.count_nonzero(frame2) - np.count_nonzero(warped_frame + frame2)
                overlap_ratio = common_area / (np.count_nonzero(warped_frame) + np.count_nonzero(frame2) - common_area)

                print(overlap_ratio)
                if overlap_ratio < 0.90:  # check if there is less than 95% overlap
                    i = j  # update the reference frame index
                    break

    else:
        # If no frame with less than 90% overlap was found, exit the loop
        break

if __name__ == "__main__":
    print(non_redundant_frames)
    print(len(non_redundant_frames))